{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images', 'labels']\n"
     ]
    }
   ],
   "source": [
    "data = np.load('notMNIST.npz')\n",
    "print(data.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with np.load('notMNIST.npz') as data :\n",
    "    Data, Target = data ['images'], data['labels']\n",
    "    posClass = 2\n",
    "    negClass = 9\n",
    "    dataIndx = (Target==posClass) + (Target==negClass)\n",
    "    Data = Data[dataIndx]/255.\n",
    "    Target = Target[dataIndx].reshape(-1, 1)\n",
    "    Target[Target==posClass] = 1\n",
    "    Target[Target==negClass] = 0\n",
    "    np.random.seed(421)\n",
    "    randIndx = np.arange(len(Data))\n",
    "    np.random.shuffle(randIndx)\n",
    "    Data, Target = Data[randIndx], Target[randIndx]\n",
    "    trainData, trainTarget = Data[:3500], Target[:3500]\n",
    "    validData, validTarget = Data[3500:3600], Target[3500:3600]\n",
    "    testData, testTarget = Data[3600:], Target[3600:]  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshaping traiing,testing and validating data\n",
    "train_X = trainData.reshape(3500,784)\n",
    "X0 = np.ones((3500,1))\n",
    "train_X = np.append(X0,train_X,axis=1)\n",
    "train_Y = trainTarget\n",
    "\n",
    "test_X = testData.reshape(145,784)\n",
    "X0 = np.ones((145,1))\n",
    "test_X = np.append(X0,test_X,axis=1) \n",
    "test_Y = testTarget\n",
    "\n",
    "validation_X = validData.reshape(100,784)\n",
    "X0 = np.ones((100,1))\n",
    "validation_X = np.append(X0,validation_X,axis=1)\n",
    "validation_Y = validTarget\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1.0/(1.0 + np.exp(-1.0 * z))    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEntropyLoss(W, b, x, y, reg):\n",
    "    #print('W:', W.shape)\n",
    "    #print('b:',b.shape)       \n",
    "    w_new = np.concatenate((b,W))    \n",
    "    loss_d = (-y * np.log(x) - (1 - y) * np.log(1 - x)).mean()              \n",
    "    loss_w = (reg/2) * (np.dot(w_new.T,w_new))  \n",
    "    tot_loss = loss_d + loss_w \n",
    "    #print(loss_d)\n",
    "    #print(loss_w)    \n",
    "    return tot_loss     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def propagate(w, b, X_train, Y_train,reg):\n",
    "    \n",
    "    m = X_train.shape[0]\n",
    "    w = np.concatenate((b,w))\n",
    "    Z= np.matmul(np.transpose(w), X_train.T)\n",
    "    A = sigmoid(Z)\n",
    "    cost = (-1.0) * np.mean(np.multiply(Y_train, np.log(A)) + np.multiply(1.0-Y_train, np.log(1.0 - A)), axis=1)                              # compute cost\n",
    "    \n",
    "    dw = np.matmul(np.transpose(X_train), np.transpose(A - Y_train)) * (1.0/m)\n",
    "    db = np.mean((A - Y_train))\n",
    "    \n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    grads = {\"dw\": dw[1:],\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent(w, b, X_train, Y_train, epochs, alpha, reg, EPS):\n",
    "    \n",
    "    loss_train =[]\n",
    "    loss_validation = []\n",
    "    iteration = []\n",
    "    loss_test = []\n",
    "    \n",
    "    theta = np.zeros((785,1))\n",
    "    theta1 = np.zeros((785,1))\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        #Initializing weight and bias\n",
    "        w = np.random.rand(784,1)\n",
    "        b = np.random.rand(1,1)\n",
    "        \n",
    "        z = np.dot(X_train, theta)\n",
    "        #print(z)\n",
    "        h = sigmoid(z)\n",
    "        #print(h)\n",
    "        gradient = np.dot(X_train.T, (h - Y_train))\n",
    "        theta = np.transpose(theta)- alpha * gradient\n",
    "        \n",
    "        z = np.dot(X_train, theta)\n",
    "        h = sigmoid(z)\n",
    "        \n",
    "        loss = crossEntropyLoss(w,b,h,Y_train,reg)\n",
    "        loss_train.append(loss)\n",
    "        iteration.append(i)\n",
    "        \n",
    "        # Cost and gradient calculation \n",
    "        grads, cost = propagate(w, b, X_train, Y_train, reg)\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule\n",
    "        w = w - alpha * dw\n",
    "        b = b - alpha * db\n",
    "        \n",
    "        if i % 1 == 0 :\n",
    "            w1 = np.random.rand(784,1)\n",
    "            b1 = np.random.rand(1,1)\n",
    "            z1 = np.dot(validation_X, theta1)\n",
    "            #print(z)\n",
    "            h1 = sigmoid(z1)\n",
    "            #print(h)\n",
    "            gradient1 = np.dot(validation_X.T, (h1 - validation_Y))\n",
    "            theta1 = np.transpose(theta1) - alpha * gradient1\n",
    "\n",
    "            z1 = np.dot(validation_X, theta1)\n",
    "            h1 = sigmoid(z1)\n",
    "            loss_val = crossEntropyLoss(w1,b1,h1,validation_Y,reg)\n",
    "            loss_validation.append(loss_val)\n",
    "            print (\"Iterations : \" + str(i) +  \"  Loss : \" + str(loss) +\" Validation Loss : \" + str(loss_val))\n",
    "        \n",
    "        if i is 0 :\n",
    "            least_loss = loss\n",
    "            error = 0 \n",
    "        else :\n",
    "            error = prev - loss\n",
    "            \n",
    "        if loss <= least_loss :\n",
    "            least_loss = loss \n",
    "            W_final = W\n",
    "            b_final = b\n",
    "        if error< EPS and i is not 0:\n",
    "            print(error)\n",
    "            break        \n",
    "\n",
    "        prev = loss\n",
    "        \n",
    "    loss_test = crossEntropyLoss(w,b,test_X,test_Y,reg)\n",
    "    #plot_print_loss(iterations, loss_train,loss_validation,loss_test)\n",
    "    return b , W, loss_train, loss_validation,loss_test, iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(train_X,train_Y):  \n",
    "    \n",
    " \n",
    "    #Initializing weight and bias\n",
    "    w = np.random.rand(784,1)\n",
    "    b = np.random.rand(1,1)\n",
    "    # Gradient descent (â‰ˆ 1 line of code)\n",
    "    b, W, loss_train, loss_validation, loss_test, iteration = grad_descent(w, b, train_X, train_Y, 5000, 0.005, reg = 0.0, EPS = 1e-7)\n",
    "    return loss_train, loss_test, loss_validation \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Urmi Joshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n",
      "C:\\Users\\Urmi Joshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in multiply\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations : 0  Loss : [[ nan]] Validation Loss : [[-8.18255291]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Urmi Joshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in less_equal\n",
      "C:\\Users\\Urmi Joshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations : 1  Loss : [[ nan]] Validation Loss : [[ nan]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Urmi Joshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:69: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations : 2  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 3  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 4  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 5  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 6  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 7  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 8  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 9  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 10  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 11  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 12  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 13  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 14  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 15  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 16  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 17  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 18  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 19  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 20  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 21  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 22  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 23  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 24  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 25  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 26  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 27  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 28  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 29  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 30  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 31  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 32  Loss : [[ nan]] Validation Loss : [[ nan]]\n",
      "Iterations : 33  Loss : [[ nan]] Validation Loss : [[ nan]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-bec9a0fb553e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-158-15c4643b8b56>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(train_X, train_Y)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Gradient descent (â‰ˆ 1 line of code)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-157-3ddef277a644>\u001b[0m in \u001b[0;36mgrad_descent\u001b[1;34m(w, b, X_train, Y_train, epochs, alpha, reg, EPS)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mloss_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0miteration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-155-470ff8603e9d>\u001b[0m in \u001b[0;36mcrossEntropyLoss\u001b[1;34m(W, b, x, y, reg)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mw_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mloss_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mloss_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_train, loss_test, loss_validation = model(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(iterations[200:], loss_train[200:])\n",
    "\n",
    "plt.plot(iterations[200:], loss_validation[200:])\n",
    "\n",
    "print(\"Test loss : \"+str(loss_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
